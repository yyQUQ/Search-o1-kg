#!/usr/bin/env python3
"""
å¿«é€Ÿå¯åŠ¨è„šæœ¬

æä¾›ä¸€é”®å¼æµ‹è¯•å’Œæ¼”ç¤ºåŠŸèƒ½ï¼Œå¸®åŠ©ç”¨æˆ·å¿«é€ŸéªŒè¯ç¯å¢ƒå¹¶ä½“éªŒé¡¹ç›®åŠŸèƒ½ã€‚
"""

import os
import sys
import json
import logging
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root / "src"))

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class QuickStartDemo:
    """å¿«é€Ÿå¯åŠ¨æ¼”ç¤º"""

    def __init__(self):
        self.project_root = project_root

    def create_sample_data(self) -> dict:
        """åˆ›å»ºç¤ºä¾‹æ•°æ®"""
        sample_data = {
            "Question": "Albert Einstein developed the theory of relativity while working at Princeton University. The famous equation E=mcÂ² shows the relationship between mass and energy.",
            "ExpectedEntities": ["Albert Einstein", "Princeton University", "E=mcÂ²", "theory of relativity"],
            "ExpectedRelations": ["worked at", "developed", "shows relationship"]
        }
        return sample_data

    def test_entity_extraction(self) -> bool:
        """æµ‹è¯•å®ä½“æŠ½å–"""
        logger.info("æµ‹è¯•å®ä½“æŠ½å–åŠŸèƒ½...")

        try:
            from knowledge_graph import EntityExtractor

            extractor = EntityExtractor()
            test_data = self.create_sample_data()

            entities = extractor.extract_entities(test_data["Question"])

            logger.info(f"âœ“ æŠ½å–åˆ° {len(entities)} ä¸ªå®ä½“:")
            for entity in entities:
                logger.info(f"  - {entity.text} ({entity.entity_type}, ç½®ä¿¡åº¦: {entity.confidence:.2f})")

            return len(entities) > 0

        except Exception as e:
            logger.error(f"âœ— å®ä½“æŠ½å–æµ‹è¯•å¤±è´¥: {e}")
            return False

    def test_knowledge_graph_building(self) -> bool:
        """æµ‹è¯•çŸ¥è¯†å›¾è°±æ„å»º"""
        logger.info("æµ‹è¯•çŸ¥è¯†å›¾è°±æ„å»ºåŠŸèƒ½...")

        try:
            from knowledge_graph import KnowledgeGraphBuilder

            builder = KnowledgeGraphBuilder()
            test_data = self.create_sample_data()

            kg = builder.build_graph_from_documents([test_data["Question"]])

            logger.info(f"âœ“ æ„å»ºçŸ¥è¯†å›¾è°±æˆåŠŸ:")
            logger.info(f"  - å®ä½“æ•°é‡: {len(kg.entities)}")
            logger.info(f"  - å…³ç³»æ•°é‡: {len(kg.relations)}")
            logger.info(f"  - å›¾èŠ‚ç‚¹æ•°: {kg.graph.number_of_nodes()}")
            logger.info(f"  - å›¾è¾¹æ•°: {kg.graph.number_of_edges()}")

            # æ˜¾ç¤ºå®ä½“è¯¦æƒ…
            for entity_id, entity in kg.entities.items():
                logger.info(f"  å®ä½“: {entity.text} ({entity.entity_type})")

            # æ˜¾ç¤ºå…³ç³»è¯¦æƒ…
            for relation in kg.relations:
                logger.info(f"  å…³ç³»: {relation.subject} --{relation.predicate}--> {relation.object}")

            return len(kg.entities) > 0

        except Exception as e:
            logger.error(f"âœ— çŸ¥è¯†å›¾è°±æ„å»ºæµ‹è¯•å¤±è´¥: {e}")
            return False

    def test_gnn_reasoning(self) -> bool:
        """æµ‹è¯•å›¾ç¥ç»ç½‘ç»œæ¨ç†"""
        logger.info("æµ‹è¯•å›¾ç¥ç»ç½‘ç»œæ¨ç†åŠŸèƒ½...")

        try:
            from knowledge_graph import KnowledgeGraphBuilder
            from gnn_reasoning import GraphReasoningEngine, GraphEmbeddingConfig

            # æ„å»ºæµ‹è¯•å›¾è°±
            builder = KnowledgeGraphBuilder()
            test_data = self.create_sample_data()
            kg = builder.build_graph_from_documents([test_data["Question"]])

            # åˆ›å»ºæ¨ç†å¼•æ“
            config = GraphEmbeddingConfig(
                hidden_dim=32,
                output_dim=16,
                num_layers=2,
                dropout=0.1
            )
            engine = GraphReasoningEngine(kg, config)

            # æµ‹è¯•å®ä½“é“¾æ¥
            question = "Where did Einstein work?"
            linked_entities = engine.link_entities(question, top_k=3)

            logger.info(f"âœ“ é“¾æ¥åˆ° {len(linked_entities)} ä¸ªå®ä½“:")
            for entity_id, confidence in linked_entities:
                entity = kg.entities.get(entity_id)
                if entity:
                    logger.info(f"  - {entity.text} (ç½®ä¿¡åº¦: {confidence:.2f})")

            return len(linked_entities) > 0

        except Exception as e:
            logger.error(f"âœ— å›¾ç¥ç»ç½‘ç»œæ¨ç†æµ‹è¯•å¤±è´¥: {e}")
            return False

    def test_multimodal_alignment(self) -> bool:
        """æµ‹è¯•è·¨æ¨¡æ€å¯¹é½"""
        logger.info("æµ‹è¯•è·¨æ¨¡æ€å¯¹é½åŠŸèƒ½...")

        try:
            from knowledge_graph import KnowledgeGraphBuilder
            from gnn_reasoning import GraphReasoningEngine, GraphEmbeddingConfig, ReasoningStep
            from multimodal_alignment import MultimodalAligner

            # æ„å»ºæµ‹è¯•å›¾è°±
            builder = KnowledgeGraphBuilder()
            test_data = self.create_sample_data()
            kg = builder.build_graph_from_documents([test_data["Question"]])

            # åˆ›å»ºå¯¹é½å™¨
            aligner = MultimodalAligner(kg)

            # åˆ›å»ºæµ‹è¯•æ¨ç†æ­¥éª¤
            reasoning_step = ReasoningStep(
                step_id=0,
                entities=[],
                relations=["worked_at"],
                confidence=0.8,
                explanation="Einstein worked at Princeton University"
            )

            # æµ‹è¯•å¯¹é½
            reasoning_text = "Einstein was a theoretical physicist who worked at Princeton University"
            alignment = aligner.align_reasoning_step(reasoning_step, reasoning_text)

            logger.info(f"âœ“ å¯¹é½ç»“æœ:")
            logger.info(f"  - æ•´ä½“ç½®ä¿¡åº¦: {alignment.overall_confidence:.2f}")
            logger.info(f"  - å¯¹é½å®ä½“æ•°é‡: {len(alignment.aligned_entities)}")
            logger.info(f"  - å¯¹é½å…³ç³»æ•°é‡: {len(alignment.aligned_relations)}")

            for entity_align in alignment.aligned_entities:
                logger.info(f"    å®ä½“: {entity_align.entity_text} ({entity_align.entity_type}, {entity_align.confidence:.2f})")

            return alignment.overall_confidence > 0

        except Exception as e:
            logger.error(f"âœ— è·¨æ¨¡æ€å¯¹é½æµ‹è¯•å¤±è´¥: {e}")
            return False

    def run_full_demo(self) -> bool:
        """è¿è¡Œå®Œæ•´æ¼”ç¤º"""
        logger.info("å¼€å§‹å®Œæ•´åŠŸèƒ½æ¼”ç¤º...")

        test_results = {
            "entity_extraction": self.test_entity_extraction(),
            "knowledge_graph_building": self.test_knowledge_graph_building(),
            "gnn_reasoning": self.test_gnn_reasoning(),
            "multimodal_alignment": self.test_multimodal_alignment()
        }

        # ç»Ÿè®¡ç»“æœ
        passed_tests = sum(test_results.values())
        total_tests = len(test_results)

        logger.info(f"\n" + "="*50)
        logger.info("åŠŸèƒ½æµ‹è¯•ç»“æœ")
        logger.info("="*50)
        for test_name, result in test_results.items():
            status = "âœ“ é€šè¿‡" if result else "âœ— å¤±è´¥"
            logger.info(f"{test_name}: {status}")

        logger.info(f"\næ€»ä½“ç»“æœ: {passed_tests}/{total_tests} æµ‹è¯•é€šè¿‡")

        if passed_tests == total_tests:
            logger.info("ğŸ‰ æ‰€æœ‰åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼ç¯å¢ƒé…ç½®æˆåŠŸï¼")
            self.show_next_steps()
        else:
            logger.warning("âš ï¸  éƒ¨åˆ†åŠŸèƒ½æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒé…ç½®")

        return passed_tests == total_tests

    def show_next_steps(self):
        """æ˜¾ç¤ºä¸‹ä¸€æ­¥æ“ä½œ"""
        logger.info("\n" + "="*50)
        logger.info("ä¸‹ä¸€æ­¥æ“ä½œæŒ‡å—")
        logger.info("="*50)
        logger.info("1. é…ç½®APIå¯†é’¥:")
        logger.info("   - ç¼–è¾‘ .env æ–‡ä»¶ï¼Œæ·»åŠ Bing Search APIå¯†é’¥")
        logger.info("   - å¯é€‰: æ·»åŠ Jina APIå¯†é’¥")
        logger.info("")
        logger.info("2. ä¸‹è½½å®Œæ•´æ•°æ®é›†:")
        logger.info("   python scripts/download_datasets.py --dataset sample")
        logger.info("   python scripts/download_datasets.py --dataset gpqa")
        logger.info("")
        logger.info("3. è¿è¡Œå®Œæ•´æ¨ç†:")
        logger.info("   python scripts/run_search_o1_kg.py \\")
        logger.info("       --dataset_name gpqa \\")
        logger.info("       --split diamond_sample \\")
        logger.info("       --model_path microsoft/DialoGPT-medium \\")
        logger.info("       --bing_subscription_key YOUR_KEY \\")
        logger.info("       --subset_num 5")
        logger.info("")
        logger.info("4. æŸ¥çœ‹è¯¦ç»†æ–‡æ¡£:")
        logger.info("   - ä½¿ç”¨æŒ‡å—: USAGE_GUIDE.md")
        logger.info("   - é¡¹ç›®æ€»ç»“: PROJECT_SUMMARY.md")
        logger.info("   - README.md")

    def create_sample_dataset(self):
        """åˆ›å»ºæ ·æœ¬æ•°æ®é›†"""
        logger.info("åˆ›å»ºæ ·æœ¬æ•°æ®é›†...")

        sample_datasets = {
            "GPQA": [
                {
                    "Question": "What is the molecular formula of glucose?",
                    "Correct Choice": "C",
                    "A": "C5H10O5",
                    "B": "C12H22O11",
                    "C": "C6H12O6",
                    "D": "C3H6O3"
                },
                {
                    "Question": "In quantum mechanics, what principle states that certain pairs of physical properties cannot be simultaneously measured with arbitrary precision?",
                    "Correct Choice": "A",
                    "A": "Heisenberg uncertainty principle",
                    "B": "Pauli exclusion principle",
                    "C": "SchrÃ¶dinger equation",
                    "D": "Planck's constant"
                }
            ],
            "MATH500": [
                {
                    "Question": "Solve for x: 2x + 5 = 15",
                    "Answer": "x = 5",
                    "Level": "1",
                    "Subject": "Algebra"
                },
                {
                    "Question": "What is the derivative of f(x) = xÂ²?",
                    "Answer": "f'(x) = 2x",
                    "Level": "1",
                    "Subject": "Calculus"
                }
            ],
            "NQ": [
                {
                    "Question": "Who was the first president of the United States?",
                    "Answer": "George Washington"
                },
                {
                    "Question": "What is the capital of France?",
                    "Answer": "Paris"
                }
            ]
        }

        # ä¿å­˜æ ·æœ¬æ•°æ®é›†
        data_dir = self.project_root / "data"
        data_dir.mkdir(exist_ok=True)

        for dataset_name, data in sample_datasets.items():
            if dataset_name == "GPQA":
                output_path = data_dir / "GPQA" / "diamond_sample.json"
            elif dataset_name == "MATH500":
                output_path = data_dir / "MATH500" / "test_sample.json"
            else:
                output_path = data_dir / "QA_Datasets" / f"{dataset_name.lower()}_sample.json"

            output_path.parent.mkdir(parents=True, exist_ok=True)

            with open(output_path, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

            logger.info(f"âœ“ æ ·æœ¬æ•°æ®é›†å·²åˆ›å»º: {output_path}")

def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="Search-o1-KG å¿«é€Ÿå¯åŠ¨æ¼”ç¤º")
    parser.add_argument("--test", type=str, choices=["entity", "kg", "gnn", "alignment", "all"],
                        default="all", help="è¿è¡Œç‰¹å®šæµ‹è¯•")
    parser.add_argument("--create-samples", action="store_true", help="åˆ›å»ºæ ·æœ¬æ•°æ®é›†")

    args = parser.parse_args()

    demo = QuickStartDemo()

    if args.create_samples:
        demo.create_sample_dataset()
        return

    if args.test == "all":
        demo.run_full_demo()
    elif args.test == "entity":
        demo.test_entity_extraction()
    elif args.test == "kg":
        demo.test_knowledge_graph_building()
    elif args.test == "gnn":
        demo.test_gnn_reasoning()
    elif args.test == "alignment":
        demo.test_multimodal_alignment()

if __name__ == "__main__":
    main()