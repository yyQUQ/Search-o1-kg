# ğŸš€ Search-o1-KG å¿«é€Ÿå¯åŠ¨æŒ‡å—

## âš¡ 5åˆ†é’Ÿå¿«é€Ÿä½“éªŒ

### 1. ç¯å¢ƒå‡†å¤‡
```bash
cd /home/yy/projects/search-o1-kg

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n search_o1_kg python=3.9
conda activate search_o1_kg

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# ä¸‹è½½spaCyæ¨¡å‹
python -m spacy download en_core_web_sm
```

### 2. ç¯å¢ƒé…ç½®
```bash
# è‡ªåŠ¨é…ç½®ç¯å¢ƒ
python scripts/setup_environment.py --install

# æˆ–æ‰‹åŠ¨åˆ›å»º.envæ–‡ä»¶
echo "BING_SUBSCRIPTION_KEY=your_key_here" > .env
```

### 3. å¿«é€Ÿæµ‹è¯•
```bash
# æµ‹è¯•æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½
python scripts/quick_start.py --test all

# åˆ›å»ºæ ·æœ¬æ•°æ®
python scripts/quick_start.py --create-samples
```

### 4. è¿è¡Œæ¼”ç¤º
```bash
# ä½¿ç”¨æ ·æœ¬æ•°æ®è¿è¡Œï¼ˆæ— éœ€çœŸå®APIå¯†é’¥ï¼‰
python scripts/run_search_o1_kg.py \
    --dataset_name gpqa \
    --split diamond_sample \
    --model_path microsoft/DialoGPT-medium \
    --subset_num 1 \
    --max_search_limit 1
```

## ğŸ“‹ å®Œæ•´ä½¿ç”¨æµç¨‹

### æ­¥éª¤1: ç¯å¢ƒé…ç½®
```bash
# å…‹éš†é¡¹ç›®
git clone <your-repo-url>
cd search-o1-kg

# ç¯å¢ƒé…ç½®
python scripts/setup_environment.py --install

# éªŒè¯å®‰è£…
python scripts/quick_start.py --test all
```

### æ­¥éª¤2: APIå¯†é’¥é…ç½®
```bash
# ç¼–è¾‘.envæ–‡ä»¶
nano .env

# æ·»åŠ ä»¥ä¸‹å†…å®¹ï¼š
BING_SUBSCRIPTION_KEY=your_bing_key_here
JINA_API_KEY=your_jina_key_here  # å¯é€‰
```

### æ­¥éª¤3: æ•°æ®å‡†å¤‡
```bash
# ä¸‹è½½æ ·æœ¬æ•°æ®
python scripts/download_datasets.py --dataset sample

# æˆ–ä¸‹è½½å®Œæ•´æ•°æ®é›†
python scripts/download_datasets.py --dataset gpqa
python scripts/download_datasets.py --dataset math500
```

### æ­¥éª¤4: è¿è¡Œå®éªŒ
```bash
# GPQAç§‘å­¦é—®ç­”
python scripts/run_search_o1_kg.py \
    --dataset_name gpqa \
    --split diamond \
    --model_path "your_model_path" \
    --bing_subscription_key "$BING_SUBSCRIPTION_KEY" \
    --subset_num 50

# æ•°å­¦æ¨ç†
python scripts/run_search_o1_kg.py \
    --dataset_name math500 \
    --split test \
    --model_path "your_model_path" \
    --bing_subscription_key "$BING_SUBSCRIPTION_KEY" \
    --subset_num 30
```

## ğŸ¯ å…³é”®æ–‡ä»¶è¯´æ˜

| æ–‡ä»¶è·¯å¾„ | ä½œç”¨ | ä½¿ç”¨æ–¹æ³• |
|---------|------|----------|
| `scripts/run_search_o1_kg.py` | ä¸»æ¨ç†è„šæœ¬ | æ ¸å¿ƒè¿è¡Œæ–‡ä»¶ |
| `src/knowledge_graph/entity_extractor.py` | å®ä½“æŠ½å– | è‡ªåŠ¨è¯†åˆ«å®ä½“ |
| `src/gnn_reasoning/reasoning_engine.py` | å›¾æ¨ç†å¼•æ“ | çŸ¥è¯†å›¾è°±æ¨ç† |
| `src/multimodal_alignment/multimodal_aligner.py` | è·¨æ¨¡æ€å¯¹é½ | æ–‡æœ¬-å›¾è°±å¯¹é½ |

## ğŸ”§ å¸¸ç”¨å‘½ä»¤

### ç¯å¢ƒç®¡ç†
```bash
# æ£€æŸ¥ç¯å¢ƒ
python scripts/setup_environment.py --quick

# é‡æ–°å®‰è£…
python scripts/setup_environment.py --install

# æµ‹è¯•åŠŸèƒ½
python scripts/quick_start.py --test all
```

### æ•°æ®ç®¡ç†
```bash
# ä¸‹è½½æ•°æ®é›†
python scripts/download_datasets.py --dataset gpqa

# åˆ›å»ºæ ·æœ¬æ•°æ®
python scripts/quick_start.py --create-samples

# æŸ¥çœ‹æ•°æ®æ ¼å¼
python scripts/preprocess_data.py --check-format
```

### å®éªŒè¿è¡Œ
```bash
# å°è§„æ¨¡æµ‹è¯•
python scripts/run_search_o1_kg.py --subset_num 1

# ä¸­ç­‰è§„æ¨¡å®éªŒ
python scripts/run_search_o1_kg.py --subset_num 50

# å¤§è§„æ¨¡å®éªŒ
python scripts/run_search_o1_kg.py --subset_num -1  # å…¨éƒ¨æ•°æ®
```

## ğŸ“Š ç»“æœæŸ¥çœ‹

### è¾“å‡ºæ–‡ä»¶ä½ç½®
```
outputs/
â””â”€â”€ dataset.model.search_o1_kg/
    â”œâ”€â”€ test.info_extract.json  # è¯¦ç»†æ¨ç†è®°å½•
    â”œâ”€â”€ test.output.json        # æ¨¡å‹è¾“å‡º
    â””â”€â”€ test.metrics.json      # æ€§èƒ½æŒ‡æ ‡
```

### åˆ†æç»“æœ
```python
# åˆ›å»ºåˆ†æè„šæœ¬
import json

# è¯»å–ç»“æœ
with open("outputs/gpqa.model.search_o1_kg/test.info_extract.json", "r") as f:
    results = json.load(f)

print(f"å¤„ç†äº† {len(results)} ä¸ªæ ·æœ¬")
for i, result in enumerate(results[:3]):
    print(f"æ ·æœ¬ {i+1}: KGå¢å¼º = {result.get('kg_enhanced', False)}")
```

## âš ï¸ å¸¸è§é—®é¢˜

### Q: æ¨¡å‹åŠ è½½å¤±è´¥
```bash
# è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨å°æ¨¡å‹æµ‹è¯•
export MODEL_PATH="microsoft/DialoGPT-medium"
python scripts/run_search_o1_kg.py --model_path "$MODEL_PATH" --subset_num 1
```

### Q: GPUå†…å­˜ä¸è¶³
```bash
# è§£å†³æ–¹æ¡ˆï¼šå‡å°‘å‚æ•°
python scripts/run_search_o1_kg.py \
    --subset_num 1 \
    --gnn_hidden_dim 64 \
    --max_doc_len 1000
```

### Q: APIå¯†é’¥é”™è¯¯
```bash
# è§£å†³æ–¹æ¡ˆï¼šæ£€æŸ¥.envæ–‡ä»¶
cat .env
# ç¡®ä¿å¯†é’¥æ­£ç¡®ä¸”æ²¡æœ‰é¢å¤–ç©ºæ ¼
```

### Q: ä¾èµ–å®‰è£…å¤±è´¥
```bash
# è§£å†³æ–¹æ¡ˆï¼šå‡çº§pipå¹¶é‡è£…
pip install --upgrade pip
pip install -r requirements.txt --force-reinstall
```

## ğŸ“ è·å–å¸®åŠ©

1. **æŸ¥çœ‹è¯¦ç»†æ–‡æ¡£**: `USAGE_GUIDE.md`
2. **æ–‡ä»¶ç»“æ„è¯´æ˜**: `FILE_STRUCTURE.md`
3. **é¡¹ç›®æ€»ç»“**: `PROJECT_SUMMARY.md`
4. **æäº¤Issue**: GitHub Issues

## ğŸ‰ æˆåŠŸæŒ‡æ ‡

è¿è¡ŒæˆåŠŸåï¼Œä½ åº”è¯¥çœ‹åˆ°ï¼š

```
å¼€å§‹Search-o1-KGæ¨ç†ï¼Œæ•°æ®é›†: gpqa
åŠ è½½äº† X æ¡æ•°æ®
åˆå§‹åŒ–è¯­è¨€æ¨¡å‹...
åˆå§‹åŒ–çŸ¥è¯†å›¾è°±ç»„ä»¶...
-------------- Turn 1 --------------
We have 1 sequences needing generation...
Generation completed, processing outputs...
Batch processing 1 sequences with enhanced KG reasoning...
çŸ¥è¯†å›¾è°±æ„å»ºå®Œæˆï¼šX ä¸ªå®ä½“ï¼ŒY ä¸ªå…³ç³»
Search-o1-KG inference completed!
```

---

**ğŸ¯ æ­å–œï¼ä½ å·²ç»æˆåŠŸè¿è¡Œäº†Search-o1-KGï¼**

ä¸‹ä¸€æ­¥ï¼š
1. å°è¯•ä¸åŒçš„æ•°æ®é›†
2. è°ƒæ•´GNNå‚æ•°
3. åˆ†ææ¨ç†ç»“æœ
4. æ’°å†™å®éªŒæŠ¥å‘Š

**ç¥ä½ ä½¿ç”¨æ„‰å¿«ï¼** ğŸš€